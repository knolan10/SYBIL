{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "from io import BytesIO\n",
    "import xmltodict\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.table import QTable\n",
    "import astropy_healpix as ah\n",
    "import astropy.units as u\n",
    "from ligo.skymap.io import read_sky_map\n",
    "from ligo.skymap.postprocess.cosmology import dVC_dVL_for_DL\n",
    "from astropy.cosmology import Planck15 as cosmo, z_at_value\n",
    "\n",
    "from ligo.gracedb.rest import GraceDb\n",
    "g = GraceDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O4a events\n",
    "\n",
    "options to get all significan O4a mergers, or the 5 mergers considered in O4a paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 significant superevents in O4a\n"
     ]
    }
   ],
   "source": [
    "# use gracedb api call to get O4a significant superevents, but some of these have been retracted.\n",
    "\n",
    "event_iterator = g.superevents('runid: O4a SIGNIF_LOCKED')\n",
    "graceids = [superevent['superevent_id'] for superevent in event_iterator]\n",
    "\n",
    "print (len(graceids), 'significant superevents in O4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [g.superevent(id) for id in graceids]\n",
    "data = [r.json() for r in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcn_urls (ids, files):\n",
    "    \"\"\"\n",
    "    remove retracted events\n",
    "    get the most recent file for each superevent\n",
    "    \"\"\" \n",
    "\n",
    "    superevent_files = [i['links']['files'] for i in files]\n",
    "\n",
    "    event_files = [g.files(graceid).json() for graceid in ids]\n",
    "\n",
    "    file = ['none' if any('etraction' in s for s in list(files))\n",
    "            else id+'-5-Update.xml,0' if id+'-5-Update.xml,0' in list(files)\n",
    "            else id+'-5-Update.xml' if id+'-5-Update.xml' in list(files)\n",
    "            else id+'-4-Update.xml,0' if id+'-4-Update.xml,0' in list(files)\n",
    "            else id+'-4-Update.xml' if id+'-4-Update.xml' in list(files)\n",
    "            else id+'-3-Update.xml,0' if id+'-3-Update.xml,0' in list(files)\n",
    "            else id+'-2-Update.xml,0' if id+'-2-Update.xml,0' in list(files)\n",
    "            else id+'-4-Initial.xml,0' if id+'-4-Initial.xml,0' in list(files) \n",
    "            else id+'-3-Initial.xml,0' if id+'-3-Initial.xml,0' in list(files)\n",
    "            else id+'-2-Initial.xml,0' if id+'-2-Initial.xml,0' in list(files)\n",
    "            else id+'-2-Preliminary.xml,0' if id+'-2-Preliminary.xml,0' in list(files)\n",
    "            else 'none' for files, id in zip(event_files, graceids)]\n",
    "\n",
    "    urls = [i+j for i,j in zip(superevent_files, file)]\n",
    "\n",
    "    [print(x) for x in urls if \"none\" in x]\n",
    "    urls_save = [x for x in urls if \"none\" not in x]\n",
    "    \n",
    "    return(urls_save)\n",
    "\n",
    "def get_params(xml_urls):\n",
    "    \"\"\"\n",
    "    get superevent_id and skymap from event files\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(xml_urls)\n",
    "        dict=xmltodict.parse(response.text)\n",
    "        superevent_id  = [item['@value'] for item in dict['voe:VOEvent']['What']['Param'] if item.get('@name') == 'GraceID'][0]\n",
    "        skymap_url = [item['Param']['@value'] for item in dict['voe:VOEvent']['What']['Group'] if item.get('@name') == 'GW_SKYMAP'][0]\n",
    "        classification = [item for item in dict['voe:VOEvent']['What']['Group'] if item.get('@name') == 'Classification']\n",
    "        prob_bns = float([item['@value'] for item in classification[0]['Param'] if item.get('@name') == 'BNS'][0])  \n",
    "        prob_nsbh = float([item['@value'] for item in classification[0]['Param'] if item.get('@name') == 'NSBH'][0])  \n",
    "        skymap_response = requests.get(skymap_url)\n",
    "        skymap_bytes = skymap_response.content\n",
    "        skymap = Table.read(BytesIO(skymap_bytes))\n",
    "        return superevent_id, skymap_bytes, skymap, prob_bns, prob_nsbh\n",
    "    \n",
    "    except:\n",
    "        print (xml_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gracedb.ligo.org/api/superevents/S231112ag/files/none\n",
      "https://gracedb.ligo.org/api/superevents/S230830b/files/none\n",
      "https://gracedb.ligo.org/api/superevents/S230808i/files/none\n",
      "https://gracedb.ligo.org/api/superevents/S230715bw/files/none\n",
      "https://gracedb.ligo.org/api/superevents/S230712a/files/none\n",
      "https://gracedb.ligo.org/api/superevents/S230708bi/files/none\n",
      "https://gracedb.ligo.org/api/superevents/S230622ba/files/none\n"
     ]
    }
   ],
   "source": [
    "#the printed urls are retracted events or my function failed to get the correct file\n",
    "\n",
    "gcn_urls = get_gcn_urls (graceids, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns event id, skymap bytes, skymap table, prob bns, prob nsbh    \n",
    "\n",
    "params = [get_params(url) for url in gcn_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 events with prob > 0.1 for NSBH or BNS: ['S230731an', 'S230627c', 'S230529ay']\n"
     ]
    }
   ],
   "source": [
    "# get subset of mergers that are potential BNS or NSBH\n",
    "\n",
    "ns_events = [i for i in params if i[3] + i[4] > 0.1]\n",
    "ids = [i[0] for i in ns_events] \n",
    "print(f'{len(ns_events)} events with prob > 0.1 for NSBH or BNS: {ids}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergers triggered on in the O4a paper (https://arxiv.org/abs/2405.12403)\n",
    "\n",
    "O4a_urls = ['https://gracedb.ligo.org/api/superevents/S230518h/files/S230518h-4-Update.xml,0',\n",
    "            'https://gracedb.ligo.org/api/superevents/S230529ay/files/S230529ay-5-Update.xml,0',\n",
    "            'https://gracedb.ligo.org/api/superevents/S230627c/files/S230627c-4-Update.xml,0',\n",
    "            'https://gracedb.ligo.org/api/superevents/S230731an/files/S230731an-4-Update.xml,0',\n",
    "            'https://gracedb.ligo.org/api/superevents/S231113bw/files/S231113bw-4-Update.xml,0',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "O4a_params = [get_params(url) for url in O4a_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# natalya's rates calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sky_area_90_percent(skymap, skymap_bytes, target_probability=0.1):\n",
    "    m, meta = read_sky_map(skymap_bytes)\n",
    "    #skymap = Table.read(skymap_file)\n",
    "    \n",
    "    nside = meta.get('nside', hp.get_nside(m))\n",
    "    \n",
    "    sorted_indices = np.argsort(m)[::-1]\n",
    "    sorted_prob_density = m[sorted_indices]\n",
    "    cumulative_prob = np.cumsum(sorted_prob_density)\n",
    "    \n",
    "    index_target_percent = np.where(cumulative_prob >= target_probability)[0][0]\n",
    "    pixels_in_target_percent = sorted_indices[:index_target_percent+1]\n",
    "    \n",
    "    theta, phi = hp.pix2ang(nside, pixels_in_target_percent)\n",
    "    ra_deg = np.degrees(phi)\n",
    "    dec_deg = np.degrees(0.5 * np.pi - theta)\n",
    "    \n",
    "    uniq_values = skymap['UNIQ']\n",
    "    \n",
    "    level, ipix = ah.uniq_to_level_ipix(uniq_values)\n",
    "    nside_sky = ah.level_to_nside(level)\n",
    "    ra_sky, dec_sky = ah.healpix_to_lonlat(ipix, nside_sky, order='nested')\n",
    "    \n",
    "    matched_indices = []\n",
    "    for ra, dec in zip(ra_deg, dec_deg):\n",
    "        matched = np.where((np.abs(ra_sky.deg - ra) < 1e-6) & (np.abs(dec_sky.deg - dec) < 1e-6))[0]\n",
    "        if len(matched) > 0:\n",
    "            matched_indices.extend(matched)\n",
    "    \n",
    "    skymap_pixels_in_target_percent = skymap[matched_indices]\n",
    "    \n",
    "    pixel_area = hp.nside2pixarea(nside)\n",
    "    total_area_target_percent = len(pixels_in_target_percent) * pixel_area\n",
    "    total_area_target_percent_deg2 = total_area_target_percent * (180 / np.pi)**2\n",
    "    \n",
    "    plot_skymap_with_90_percent_region(m, nside, pixels_in_target_percent)\n",
    "    \n",
    "    return total_area_target_percent_deg2, skymap_pixels_in_target_percent, nside\n",
    "\n",
    "def calculate_pixel_volumes(skymap, skymap_bytes, target_probability=0.1):\n",
    "    m, meta = read_sky_map(skymap_bytes)\n",
    "    #skymap = Table.read(skymap_file)\n",
    "    \n",
    "    nside = meta.get('nside', hp.get_nside(m))\n",
    "    \n",
    "    sorted_indices = np.argsort(m)[::-1]\n",
    "    sorted_prob_density = m[sorted_indices]\n",
    "    cumulative_prob = np.cumsum(sorted_prob_density)\n",
    "    \n",
    "    index_target_percent = np.where(cumulative_prob >= target_probability)[0][0]\n",
    "    pixels_in_target_percent = sorted_indices[:index_target_percent+1]\n",
    "    \n",
    "    theta, phi = hp.pix2ang(nside, pixels_in_target_percent)\n",
    "    ra_deg = np.degrees(phi)\n",
    "    dec_deg = np.degrees(0.5 * np.pi - theta)\n",
    "    \n",
    "    level, ipix = ah.uniq_to_level_ipix(skymap['UNIQ'])\n",
    "    nside_sky = ah.level_to_nside(level)\n",
    "    ra_sky, dec_sky = ah.healpix_to_lonlat(ipix, nside_sky, order='nested')\n",
    "    \n",
    "    matched_indices = []\n",
    "    for ra, dec in zip(ra_deg, dec_deg):\n",
    "        matched = np.where((np.abs(ra_sky.deg - ra) < 1e-6) & (np.abs(dec_sky.deg - dec) < 1e-6))[0]\n",
    "        if len(matched) > 0:\n",
    "            matched_indices.extend(matched)\n",
    "    \n",
    "    matched_indices = np.array(matched_indices)\n",
    "    \n",
    "    volumes = np.zeros(len(matched_indices))\n",
    "    \n",
    "     # Loop over each matched pixel to calculate volumes\n",
    "    for i, idx in enumerate(matched_indices):\n",
    "        pixel_area_deg2 =  hp.nside2pixarea(nside, degrees=True)\n",
    "        #Convert square degrees to square arcseconds\n",
    "        area_arcsec2 = pixel_area_deg2 * (3600**2)\n",
    "        #Convert square arcseconds to square parsecs using the conversion factor\n",
    "        area_pc2 = area_arcsec2 / (0.2679**2)\n",
    "        #Convert square parsecs to square megaparsecs (Mpc^2)\n",
    "        area_mpc2 = area_pc2 / 10**12\n",
    "        \n",
    "        dist = 1000\n",
    "        # Calculate the volume for this pixel\n",
    "        volumes[i] = (area_mpc2 * dist)*10e-9    # Gpc^3\n",
    "    \n",
    "    # Create a structured array to store pixel index, volume, and corresponding distances\n",
    "    pixel_volumes = np.zeros(len(matched_indices), dtype=[('pixel_index', int), ('volume_Gpc3', float)])\n",
    "    pixel_volumes['pixel_index'] = matched_indices\n",
    "    pixel_volumes['volume_Gpc3'] = volumes\n",
    "\n",
    "    return pixel_volumes\n",
    "\n",
    "def calculate_expected_transients_poisson(volumes, transients_rates, time_window_days=2):\n",
    "    total_expected_transients = {transient: 0 for transient in transients_rates}\n",
    "    time_window_years = time_window_days / 365.25\n",
    "    \n",
    "    for volume in volumes:\n",
    "        for transient, rate in transients_rates.items():\n",
    "            T = time_window_years\n",
    "            expected_events = rate * volume * T\n",
    "            \n",
    "            sampled_events = np.random.poisson(expected_events)\n",
    "            total_expected_transients[transient] += sampled_events\n",
    "    \n",
    "    return total_expected_transients\n",
    "\n",
    "def plot_skymap_with_90_percent_region(m, nside, pixels_in_target_percent):\n",
    "    theta, phi = hp.pix2ang(nside, np.arange(len(m)))\n",
    "    ra_rad = phi\n",
    "    dec_rad = 0.5 * np.pi - theta\n",
    "\n",
    "    ra_rad = ra_rad - np.pi\n",
    "\n",
    "    theta_90, phi_90 = hp.pix2ang(nside, pixels_in_target_percent)\n",
    "    ra_90 = phi_90 - np.pi\n",
    "    dec_90 = 0.5 * np.pi - theta_90\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(111, projection='aitoff')\n",
    "    ax.grid(True)\n",
    "\n",
    "    sc = ax.scatter(ra_rad, dec_rad, c=m, s=5, cmap='Reds', alpha=0.7, linewidth=0)\n",
    "\n",
    "    ax.scatter(ra_90, dec_90, color='blue', marker='o', s=2, label='90% Probability Region')\n",
    "\n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation=\"horizontal\", fraction=0.06, pad=0.1)\n",
    "    cbar.set_label('Probability Density')\n",
    "\n",
    "    plt.title(\"Skymap in Aitoff Projection with 90% Region\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transients (gwevent):\n",
    "    \"\"\"\n",
    "    predict contaminant rates given a skymap\n",
    "    \"\"\"\n",
    "    print(f\"Calculating expected transients for event {gwevent[0]}\")\n",
    "    skymap_bytes = BytesIO(gwevent[1])\n",
    "    skymap = gwevent[2]\n",
    "\n",
    "    transients_rates = {\n",
    "        'SNIa': 2.35e4,  # per Gpc^3 per year\n",
    "        'CCSN': 1.01e5,\n",
    "        'SLSN': 5.6,\n",
    "        'KN': 5e3,\n",
    "        'GRB_on_axis': 1,\n",
    "        'GRB_off_axis': 7,\n",
    "        'CV': 1e6,  # Use a refined rate near the galactic plane\n",
    "    }\n",
    "\n",
    "    # Calculate volumes for the 90% area\n",
    "    pixel_volumes_in_90_percent = calculate_pixel_volumes(skymap, skymap_bytes, target_probability=0.1)\n",
    "\n",
    "    # Run multiple simulations\n",
    "    num_simulations = 10\n",
    "    all_simulations = {transient: [] for transient in transients_rates}\n",
    "\n",
    "    time_window_days = 200  # Define the time window\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        # Calculate expected transients in the 90% probability region with time window integration\n",
    "        total_expected_transients = calculate_expected_transients_poisson(pixel_volumes_in_90_percent['volume_Gpc3'], transients_rates, time_window_days)\n",
    "        \n",
    "        # Store the results of each simulation\n",
    "        for transient, count in total_expected_transients.items():\n",
    "            all_simulations[transient].append(count)\n",
    "\n",
    "    # Calculate mean and standard deviation for each transient type\n",
    "    mean_transients = {transient: np.mean(all_simulations[transient]) for transient in transients_rates}\n",
    "    std_transients = {transient: np.std(all_simulations[transient]) for transient in transients_rates}\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Mean and standard deviation of sampled transients over {time_window_days} days with {num_simulations} simulations:')\n",
    "    for transient in transients_rates:\n",
    "        print(f\"{transient}: Mean = {mean_transients[transient]:.15f}, Std = {std_transients[transient]:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expected transients for event S230518h\n",
      "Mean and standard deviation of sampled transients over 200 days with 10 simulations:\n",
      "SNIa: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CCSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "SLSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "KN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_on_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_off_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CV: Mean = 0.000000000000000, Std = 0.000000000000000\n"
     ]
    }
   ],
   "source": [
    "get_transients(O4a_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expected transients for event S230529ay\n",
      "Mean and standard deviation of sampled transients over 200 days with 10 simulations:\n",
      "SNIa: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CCSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "SLSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "KN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_on_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_off_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CV: Mean = 1.500000000000000, Std = 1.360147050873544\n"
     ]
    }
   ],
   "source": [
    "get_transients(O4a_params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expected transients for event S230627c\n",
      "Mean and standard deviation of sampled transients over 200 days with 10 simulations:\n",
      "SNIa: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CCSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "SLSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "KN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_on_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_off_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CV: Mean = 0.000000000000000, Std = 0.000000000000000\n"
     ]
    }
   ],
   "source": [
    "get_transients(O4a_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expected transients for event S230731an\n",
      "Mean and standard deviation of sampled transients over 200 days with 10 simulations:\n",
      "SNIa: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CCSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "SLSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "KN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_on_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_off_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CV: Mean = 0.000000000000000, Std = 0.000000000000000\n"
     ]
    }
   ],
   "source": [
    "get_transients(O4a_params[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expected transients for event S231113bw\n",
      "Mean and standard deviation of sampled transients over 200 days with 10 simulations:\n",
      "SNIa: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CCSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "SLSN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "KN: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_on_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_off_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "CV: Mean = 0.100000000000000, Std = 0.300000000000000\n"
     ]
    }
   ],
   "source": [
    "get_transients(O4a_params[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My rates calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get volume per pixel in 90% region of given skymap\n",
    "\n",
    "#to do - look at stats: total volume, avg volume per pixel, max volume, min volume   \n",
    "#could check how different 90% volume is from 90% area, which im currently using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/lpsinger/ligo.skymap/blob/a8da314dcb078f7866f4178cbd523b9844cceae0/ligo/skymap/distance.py#L701\n",
    "\n",
    "def parameters_to_marginal_moments(prob, distmu, distsigma):\n",
    "    \"\"\"Calculate the marginal (integrated all-sky) mean and standard deviation\n",
    "    of distance from the ansatz parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prob : `numpy.ndarray`\n",
    "        Marginal probability (pix^-2)\n",
    "    distmu : `numpy.ndarray`\n",
    "        Distance location parameter (Mpc)\n",
    "    distsigma : `numpy.ndarray`\n",
    "        Distance scale parameter (Mpc)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distmean : float\n",
    "        Mean distance (Mpc)\n",
    "    diststd : float\n",
    "        Std. deviation of distance (Mpc)\n",
    "\n",
    "    \"\"\"\n",
    "    good = np.isfinite(prob) & np.isfinite(distmu) & np.isfinite(distsigma)\n",
    "    prob = prob[good]\n",
    "    distmu = distmu[good]\n",
    "    distsigma = distsigma[good]\n",
    "    distmean, diststd, _ = parameters_to_moments(distmu, distsigma)\n",
    "    rbar = (prob * distmean).sum()\n",
    "    r2bar = (prob * (np.square(diststd) + np.square(distmean))).sum()\n",
    "    return rbar, np.sqrt(r2bar - np.square(rbar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/lpsinger/ligo.skymap/blob/a8da314dcb078f7866f4178cbd523b9844cceae0/ligo/skymap/postprocess/crossmatch.py\n",
    "\n",
    "def get_skymap_voxels(skymap, contour=0.9, cosmology=True):\n",
    "    \"\"\"\n",
    "    Determine the volume per pixel in the 90% region of a skymap\n",
    "    This volume is associated with a sky position and can be used with positionally nonuniform rates\n",
    "    \"\"\"\n",
    "    # get specified countour of skymap, drop other pixels\n",
    "    skymap.sort('PROBDENSITY', reverse = True)\n",
    "    level, ipix = ah.uniq_to_level_ipix(skymap['UNIQ']) # ipix = sky location\n",
    "    nside = ah.level_to_nside(level) # nside = multi-order pixel resolution\n",
    "    pixel_area = ah.nside_to_pixel_area(ah.level_to_nside(level)) # pixel area in steradians\n",
    "    prob = pixel_area * skymap['PROBDENSITY']\n",
    "    cumprob = np.cumsum(prob)\n",
    "    i = cumprob.searchsorted(contour)\n",
    "    dA = pixel_area[:i].to_value(u.deg**2) #areas in deg**2 per pixel for only pixels in countour\n",
    "    #convert dA to mpc^2 ?\n",
    "    d = skymap.meta['DISTMEAN']\n",
    "\n",
    "    #get ra and dec in degrees associated with each pixel\n",
    "    ra, dec = ah.healpix_to_lonlat(ipix[:i], nside[:i])\n",
    "    radeg = [r.deg for r in ra]\n",
    "    decdeg = [d.deg for d in dec]\n",
    "\n",
    "    # Calculate volume of each voxel, defined as the region within the\n",
    "    # HEALPix pixel and contained within the two centric spherical shells\n",
    "    # with radii (r - d_r / 2) and (r + d_r / 2).\n",
    "    r = 500 #mpc\n",
    "    d_r = 1000 #mpc\n",
    "    dV = (np.square(r) + np.square(d_r) / 12) * d_r * dA.reshape(-1, 1) #naive euclidean volume\n",
    "\n",
    "    dV2 = 4/3 * np.pi * 1000**3 * dA.reshape(-1, 1)/(4 * np.pi * d)\n",
    "\n",
    "    # Calculate probability density per unit volume.\n",
    "    if cosmology:\n",
    "        dV *= dVC_dVL_for_DL(r) #comoving volume\n",
    "    \n",
    "    V = np.sum(dV2)\n",
    "\n",
    "    print(f'total volume: {V} Mpc3') \n",
    "    return V, dV2, radeg, decdeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting volume for S230518h\n",
      "total volume: 750825618.1214184 Mpc3\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(f'getting volume for {O4a_params[index][0]}')\n",
    "voxels0 = get_skymap_voxels(O4a_params[index][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting euclidean volume for S230518h\n",
      "total volume: 750825618.1214184 Mpc3\n"
     ]
    }
   ],
   "source": [
    "# check to validate assumption comoving volume is necessary at these redshifts\n",
    "\n",
    "print(f'getting euclidean volume for {O4a_params[index][0]}')\n",
    "voxels0_euclidean = get_skymap_voxels(O4a_params[index][2], cosmology = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting volume for S230529ay\n",
      "total volume: 41475017540.92716 Mpc3\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(f'getting volume for {O4a_params[index][0]}')\n",
    "voxels1 = get_skymap_voxels(O4a_params[index][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting volume for S230627c\n",
      "total volume: 93330692.82891332 Mpc3\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "print(f'getting volume for {O4a_params[index][0]}')\n",
    "voxels2 = get_skymap_voxels(O4a_params[index][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting volume for S230731an\n",
      "total volume: 199260729.54851672 Mpc3\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "print(f'getting volume for {O4a_params[index][0]}')\n",
    "voxels3 = get_skymap_voxels(O4a_params[index][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting volume for S231113bw\n",
      "total volume: 481454999.8597008 Mpc3\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "print(f'getting volume for {O4a_params[index][0]}')\n",
    "voxels4 = get_skymap_voxels(O4a_params[index][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish this code\n",
    "\n",
    "def plotter (ra, dec, url):\n",
    "    center = SkyCoord(ra=0*u.degree, dec=0*u.degree, frame='icrs')\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=100)\n",
    "\n",
    "    ax = plt.axes(\n",
    "        [0.05, 0.05, 0.9, 0.9],\n",
    "        projection='astro globe',\n",
    "        center=center)\n",
    "\n",
    "    ax_inset = plt.axes(\n",
    "        [0.7, 0.45, 0.7, 0.7],\n",
    "        projection='astro zoom',\n",
    "        center=center,\n",
    "        radius=7*u.deg)\n",
    "\n",
    "    for key in ['ra', 'dec']:\n",
    "        ax_inset.coords[key].set_ticklabel_visible(False)\n",
    "        ax_inset.coords[key].set_ticks_visible(False)\n",
    "    ax.grid()\n",
    "    ax.mark_inset_axes(ax_inset)\n",
    "    ax.connect_inset_axes(ax_inset, 'upper left')\n",
    "    ax.connect_inset_axes(ax_inset, 'lower left')\n",
    "    ax_inset.scalebar((0.1, 0.1), 5 * u.deg).label()\n",
    "\n",
    "    ax.imshow_hpx(url, cmap='cylon')\n",
    "    ax_inset.imshow_hpx(url, cmap='cylon')\n",
    "\n",
    "    ax_inset.plot(\n",
    "        ra, dec, 'X', color='blue', \n",
    "        transform=ax_inset.get_transform('world'),\n",
    "        markersize=1,\n",
    "        markeredgewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use volume time rates to get rates per time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_transients_poisson(volumes, transients_rates, time_window_days):\n",
    "    total_expected_transients = {transient: 0 for transient in transients_rates}\n",
    "    time_window_years = time_window_days / 365.25\n",
    "    \n",
    "    for volume in volumes:\n",
    "        volume_gpc = volume * 10e-9 #convert Mpc^3 to Gpc^3\n",
    "\n",
    "        for transient, rate in transients_rates.items():\n",
    "            T = time_window_years\n",
    "            expected_events = rate * volume_gpc * T\n",
    "            \n",
    "            sampled_events = np.random.poisson(expected_events)\n",
    "            total_expected_transients[transient] += sampled_events\n",
    "    \n",
    "    return total_expected_transients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transients (gwevent, volume, rates, time_window_days=2, num_simulations=10):    \n",
    "    \"\"\"\n",
    "    predict contaminant rates given a skymap\n",
    "    \"\"\"\n",
    "    print(f\"Calculating expected transients for event {gwevent[0]}\")\n",
    "\n",
    "    # Run multiple simulations\n",
    "    all_simulations = {transient: [] for transient in rates}\n",
    "    \n",
    "    for _ in range(num_simulations):\n",
    "        total_expected_transients = calculate_expected_transients_poisson(volume, rates, time_window_days)\n",
    "        \n",
    "        # Store the results of each simulation\n",
    "        for transient, count in total_expected_transients.items():\n",
    "            all_simulations[transient].append(count)\n",
    "\n",
    "    # Calculate mean and standard deviation for each transient type\n",
    "    mean_transients = {transient: np.mean(all_simulations[transient]) for transient in rates}\n",
    "    std_transients = {transient: np.std(all_simulations[transient]) for transient in rates}\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Mean and standard deviation of sampled transients over {time_window_days} days with {num_simulations} simulations:')\n",
    "    for transient in rates:\n",
    "        print(f\"{transient}: Mean = {mean_transients[transient]:.15f}, Std = {std_transients[transient]:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transients_rates = {\n",
    "    'SNIa': 2.35e4,  # per Gpc^3 per year\n",
    "    'CCSN': 1.01e5,\n",
    "    'SLSN': 5.6,\n",
    "    'KN': 5e3,\n",
    "    'GRB_on_axis': 1,\n",
    "    'GRB_off_axis': 7,\n",
    "    'CV': 1e6,  # Use a refined rate near the galactic plane\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expected transients for event S230518h\n",
      "Mean and standard deviation of sampled transients over 2 days with 10 simulations:\n",
      "SNIa: Mean = 612.899999999999977, Std = 31.554555930958685\n",
      "CCSN: Mean = 2651.699999999999818, Std = 55.020087240934103\n",
      "SLSN: Mean = 0.200000000000000, Std = 0.400000000000000\n",
      "KN: Mean = 130.000000000000000, Std = 10.158740079360236\n",
      "GRB_on_axis: Mean = 0.000000000000000, Std = 0.000000000000000\n",
      "GRB_off_axis: Mean = 0.200000000000000, Std = 0.400000000000000\n",
      "CV: Mean = 26484.700000000000728, Std = 130.975608416223821\n"
     ]
    }
   ],
   "source": [
    "transients0 = get_transients(O4a_params[0], voxels0[1], transients_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps: add galactic latitude consideration to rates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
